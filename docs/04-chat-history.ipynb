{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RV62cSjthjJ3"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aurelio-labs/semantic-router/blob/main/docs/04-chat-history.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/aurelio-labs/semantic-router/blob/main/docs/04-chat-history.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYYK03GXhjJ4"
      },
      "source": [
        "## Install Prerequisites"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g80rO0b2hjJ5",
        "outputId": "a77a560a-0cca-4140-f536-6f0981b1ccfe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastembed\n",
            "  Using cached fastembed-0.2.7-py3-none-any.whl (27 kB)\n",
            "Collecting huggingface-hub<0.21,>=0.20 (from fastembed)\n",
            "  Using cached huggingface_hub-0.20.3-py3-none-any.whl (330 kB)\n",
            "Collecting loguru<0.8.0,>=0.7.2 (from fastembed)\n",
            "  Using cached loguru-0.7.2-py3-none-any.whl (62 kB)\n",
            "Requirement already satisfied: numpy>=1.21 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from fastembed) (1.26.4)\n",
            "Collecting onnx<2.0.0,>=1.15.0 (from fastembed)\n",
            "  Using cached onnx-1.16.0-cp311-cp311-win_amd64.whl (14.4 MB)\n",
            "Collecting onnxruntime<2.0.0,>=1.17.0 (from fastembed)\n",
            "  Using cached onnxruntime-1.17.3-cp311-cp311-win_amd64.whl (5.6 MB)\n",
            "Requirement already satisfied: requests<3.0,>=2.31 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from fastembed) (2.31.0)\n",
            "Collecting tokenizers<0.16,>=0.15 (from fastembed)\n",
            "  Using cached tokenizers-0.15.2-cp311-none-win_amd64.whl (2.2 MB)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from fastembed) (4.66.2)\n",
            "Collecting filelock (from huggingface-hub<0.21,>=0.20->fastembed)\n",
            "  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<0.21,>=0.20->fastembed)\n",
            "  Using cached fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from huggingface-hub<0.21,>=0.20->fastembed) (24.0)\n",
            "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from loguru<0.8.0,>=0.7.2->fastembed) (0.4.6)\n",
            "Collecting win32-setctime>=1.0.0 (from loguru<0.8.0,>=0.7.2->fastembed)\n",
            "  Using cached win32_setctime-1.1.0-py3-none-any.whl (3.6 kB)\n",
            "Collecting protobuf>=3.20.2 (from onnx<2.0.0,>=1.15.0->fastembed)\n",
            "  Using cached protobuf-5.26.1-cp310-abi3-win_amd64.whl (420 kB)\n",
            "Collecting coloredlogs (from onnxruntime<2.0.0,>=1.17.0->fastembed)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting flatbuffers (from onnxruntime<2.0.0,>=1.17.0->fastembed)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Collecting sympy (from onnxruntime<2.0.0,>=1.17.0->fastembed)\n",
            "  Using cached sympy-1.12-py3-none-any.whl (5.7 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from requests<3.0,>=2.31->fastembed) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from requests<3.0,>=2.31->fastembed) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from requests<3.0,>=2.31->fastembed) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\siraj\\documents\\personal\\work\\aurelio\\virtual environments\\semantic_router_3\\lib\\site-packages (from requests<3.0,>=2.31->fastembed) (2024.2.2)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Collecting mpmath>=0.19 (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed)\n",
            "  Using cached pyreadline3-3.4.1-py3-none-any.whl (95 kB)\n",
            "Installing collected packages: pyreadline3, mpmath, flatbuffers, win32-setctime, sympy, protobuf, humanfriendly, fsspec, filelock, onnx, loguru, huggingface-hub, coloredlogs, tokenizers, onnxruntime, fastembed\n",
            "Successfully installed coloredlogs-15.0.1 fastembed-0.2.7 filelock-3.14.0 flatbuffers-24.3.25 fsspec-2024.3.1 huggingface-hub-0.20.3 humanfriendly-10.0 loguru-0.7.2 mpmath-1.3.0 onnx-1.16.0 onnxruntime-1.17.3 protobuf-5.26.1 pyreadline3-3.4.1 sympy-1.12 tokenizers-0.15.2 win32-setctime-1.1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~rotobuf (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 2.17.0 requires fsspec[http]<=2023.10.0,>=2023.1.0, but you have fsspec 2024.3.1 which is incompatible.\n",
            "WARNING: Ignoring invalid distribution ~ (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~illow (C:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages)\n",
            "\n",
            "[notice] A new release of pip is available: 23.1.2 -> 24.0\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "!pip install fastembed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDH-GntqhjJ6"
      },
      "source": [
        "# Considering Chat History"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvYSb3IChjJ6"
      },
      "source": [
        "Applying semantic-router to the most recent interaction in a conversation can work for many cases but it misses scenarios where information provided in the latest interaction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1QiIxppVhjJ6",
        "outputId": "fd19a5bf-77e4-4df4-dae1-10fb532c6c81"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Siraj\\Documents\\Personal\\Work\\Aurelio\\Virtual Environments\\semantic_router_3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Fetching 5 files: 100%|██████████| 5/5 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([(1, 'User: Hello! Can you tell me the latest news headlines?'),\n",
              "  (1, 'Bot: Hi! Sure, here are the top news headlines for today...'),\n",
              "  (2,\n",
              "   \"User: That's quite interesting. I'm also looking for some new music to listen to.\"),\n",
              "  (3, 'Bot: What genre do you prefer?'),\n",
              "  (4, 'User: I like pop music.'),\n",
              "  (5, 'Bot: You might enjoy the latest album by Dua Lipa.'),\n",
              "  (6,\n",
              "   \"User: I'll give it a listen. Also, I'm planning a trip and need some travel tips.\"),\n",
              "  (6, 'Bot: Sure, where are you planning to go?'),\n",
              "  (6, \"User: I'm thinking of visiting Italy.\"),\n",
              "  (6,\n",
              "   'Bot: Italy is a beautiful country. Make sure to visit the Colosseum in Rome and the canals in Venice.'),\n",
              "  (7,\n",
              "   'User: Those sound like great suggestions. I also need some help with my diet.'),\n",
              "  (7, 'Bot: What kind of diet are you following?'),\n",
              "  (7, \"User: I'm trying to eat more protein.\"),\n",
              "  (7,\n",
              "   'Bot: Include lean meats, eggs, and legumes in your diet for a protein boost.'),\n",
              "  (8, \"User: Thanks for the tips! I'll talk to you later.\"),\n",
              "  (8,\n",
              "   \"Bot: You're welcome! Don't hesitate to reach out if you need more help.\"),\n",
              "  (8, 'User: I appreciate it. Goodbye!'),\n",
              "  (8, 'Bot: Goodbye! Take care!')],\n",
              " [DocumentSplit(docs=['User: Hello! Can you tell me the latest news headlines?', 'Bot: Hi! Sure, here are the top news headlines for today...'], is_triggered=True, triggered_score=0.6881566496849609, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=[\"User: That's quite interesting. I'm also looking for some new music to listen to.\"], is_triggered=True, triggered_score=0.6483805726099723, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=['Bot: What genre do you prefer?'], is_triggered=True, triggered_score=0.6016203292938812, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=['User: I like pop music.'], is_triggered=True, triggered_score=0.681239312154468, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=['Bot: You might enjoy the latest album by Dua Lipa.'], is_triggered=True, triggered_score=0.6766231070914372, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=[\"User: I'll give it a listen. Also, I'm planning a trip and need some travel tips.\", 'Bot: Sure, where are you planning to go?', \"User: I'm thinking of visiting Italy.\", 'Bot: Italy is a beautiful country. Make sure to visit the Colosseum in Rome and the canals in Venice.'], is_triggered=True, triggered_score=0.6772425275909593, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=['User: Those sound like great suggestions. I also need some help with my diet.', 'Bot: What kind of diet are you following?', \"User: I'm trying to eat more protein.\", 'Bot: Include lean meats, eggs, and legumes in your diet for a protein boost.'], is_triggered=True, triggered_score=0.613774528067004, token_count=None, metadata=None),\n",
              "  DocumentSplit(docs=[\"User: Thanks for the tips! I'll talk to you later.\", \"Bot: You're welcome! Don't hesitate to reach out if you need more help.\", 'User: I appreciate it. Goodbye!', 'Bot: Goodbye! Take care!'], is_triggered=False, triggered_score=None, token_count=None, metadata=None)])"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from semantic_router.schema import Message\n",
        "from semantic_router.encoders import FastEmbedEncoder\n",
        "from semantic_router.text import Conversation\n",
        "\n",
        "\n",
        "messages = [\n",
        "    \"User: Hello! Can you tell me the latest news headlines?\",\n",
        "    \"Bot: Hi! Sure, here are the top news headlines for today...\",\n",
        "    \"User: That's quite interesting. I'm also looking for some new music to listen to.\",\n",
        "    \"Bot: What genre do you prefer?\",\n",
        "    \"User: I like pop music.\",\n",
        "    \"Bot: You might enjoy the latest album by Dua Lipa.\",\n",
        "    \"User: I'll give it a listen. Also, I'm planning a trip and need some travel tips.\",\n",
        "    \"Bot: Sure, where are you planning to go?\",\n",
        "    \"User: I'm thinking of visiting Italy.\",\n",
        "    \"Bot: Italy is a beautiful country. Make sure to visit the Colosseum in Rome and the canals in Venice.\",\n",
        "    \"User: Those sound like great suggestions. I also need some help with my diet.\",\n",
        "    \"Bot: What kind of diet are you following?\",\n",
        "    \"User: I'm trying to eat more protein.\",\n",
        "    \"Bot: Include lean meats, eggs, and legumes in your diet for a protein boost.\",\n",
        "    \"User: Thanks for the tips! I'll talk to you later.\",\n",
        "    \"Bot: You're welcome! Don't hesitate to reach out if you need more help.\",\n",
        "    \"User: I appreciate it. Goodbye!\",\n",
        "    \"Bot: Goodbye! Take care!\",\n",
        "]\n",
        "\n",
        "encoder = FastEmbedEncoder(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "convo = Conversation(\n",
        "    messages=[\n",
        "        Message(role=m.split(\": \")[0], content=m.split(\": \")[1]) for m in messages\n",
        "    ]\n",
        ")\n",
        "\n",
        "convo.configure_splitter(\n",
        "    encoder=encoder, threshold=0.72, split_method=\"cumulative_similarity\"\n",
        ")\n",
        "\n",
        "convo.split_by_topic()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dins-sW0hjJ7"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ml",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
